{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unido = pd.read_csv('../datos/datos_unidos_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_espacios(columna):  \n",
    "    try:\n",
    "\n",
    "        patron_espacios = \"\\s*,\\S+\"\n",
    "        return re.sub(patron_espacios, \", \", columna)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_comas(columna):\n",
    "    try:\n",
    "        patron_comas = '(,\\s)a'\n",
    "        return re.sub(patron_comas, \"; a\", columna)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unido['Q24'] = df_unido['Q24'].apply(separar_comas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' None of these activities are an important part of my role at work',\n",
       "       ' Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data',\n",
       "       ' Do research that advances the state of the art of machine learning',\n",
       "       'Analyze and understand data to influence product or business decisions, Build prototypes to explore applying machine learning to new areas',\n",
       "       nan,\n",
       "       ' Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build prototypes to explore applying machine learning to new areas',\n",
       "       'Analyze and understand data to influence product or business decisions',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data',\n",
       "       ' Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build prototypes to explore applying machine learning to new areas, Experimentation and iteration to improve existing ML models',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run a machine learning service that operationally improves my product or workflows',\n",
       "       'Analyze and understand data to influence product or business decisions, Build prototypes to explore applying machine learning to new areas, Do research that advances the state of the art of machine learning',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build prototypes to explore applying machine learning to new areas, Build and/or run a machine learning service that operationally improves my product or workflows, Experimentation and iteration to improve existing ML models, Do research that advances the state of the art of machine learning',\n",
       "       'Analyze and understand data to influence product or business decisions, Build prototypes to explore applying machine learning to new areas, Experimentation and iteration to improve existing ML models',\n",
       "       ' Build and/or run a machine learning service that operationally improves my product or workflows',\n",
       "       ' Experimentation and iteration to improve existing ML models, Do research that advances the state of the art of machine learning',\n",
       "       'Analyze and understand data to influence product or business decisions, Build prototypes to explore applying machine learning to new areas, Build and/or run a machine learning service that operationally improves my product or workflows, Experimentation and iteration to improve existing ML models',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build prototypes to explore applying machine learning to new areas, Build and/or run a machine learning service that operationally improves my product or workflows',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build prototypes to explore applying machine learning to new areas',\n",
       "       ' Other',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build prototypes to explore applying machine learning to new areas, Build and/or run a machine learning service that operationally improves my product or workflows, Experimentation and iteration to improve existing ML models',\n",
       "       'Analyze and understand data to influence product or business decisions, Build prototypes to explore applying machine learning to new areas, Build and/or run a machine learning service that operationally improves my product or workflows, Do research that advances the state of the art of machine learning',\n",
       "       'Analyze and understand data to influence product or business decisions, Do research that advances the state of the art of machine learning',\n",
       "       'Analyze and understand data to influence product or business decisions, Experimentation and iteration to improve existing ML models',\n",
       "       ' Build prototypes to explore applying machine learning to new areas, Build and/or run a machine learning service that operationally improves my product or workflows, Experimentation and iteration to improve existing ML models',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Experimentation and iteration to improve existing ML models, Do research that advances the state of the art of machine learning',\n",
       "       ' Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build and/or run a machine learning service that operationally improves my product or workflows, Other',\n",
       "       ' Build prototypes to explore applying machine learning to new areas, Experimentation and iteration to improve existing ML models',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Do research that advances the state of the art of machine learning',\n",
       "       ' Build prototypes to explore applying machine learning to new areas',\n",
       "       ' Experimentation and iteration to improve existing ML models',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run a machine learning service that operationally improves my product or workflows, Experimentation and iteration to improve existing ML models',\n",
       "       ' Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build and/or run a machine learning service that operationally improves my product or workflows, Do research that advances the state of the art of machine learning',\n",
       "       ' Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build prototypes to explore applying machine learning to new areas, Build and/or run a machine learning service that operationally improves my product or workflows',\n",
       "       'Analyze and understand data to influence product or business decisions, Experimentation and iteration to improve existing ML models, Do research that advances the state of the art of machine learning',\n",
       "       'Analyze and understand data to influence product or business decisions, Build prototypes to explore applying machine learning to new areas, Build and/or run a machine learning service that operationally improves my product or workflows',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build prototypes to explore applying machine learning to new areas, Do research that advances the state of the art of machine learning',\n",
       "       ' Build prototypes to explore applying machine learning to new areas, Build and/or run a machine learning service that operationally improves my product or workflows, Do research that advances the state of the art of machine learning',\n",
       "       ' Build and/or run a machine learning service that operationally improves my product or workflows, Experimentation and iteration to improve existing ML models, Do research that advances the state of the art of machine learning',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build and/or run a machine learning service that operationally improves my product or workflows',\n",
       "       ' Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Experimentation and iteration to improve existing ML models',\n",
       "       ' Build and/or run a machine learning service that operationally improves my product or workflows, Experimentation and iteration to improve existing ML models',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Experimentation and iteration to improve existing ML models',\n",
       "       ' Build prototypes to explore applying machine learning to new areas, Build and/or run a machine learning service that operationally improves my product or workflows, Experimentation and iteration to improve existing ML models, Do research that advances the state of the art of machine learning',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build and/or run a machine learning service that operationally improves my product or workflows, Do research that advances the state of the art of machine learning',\n",
       "       'Analyze and understand data to influence product or business decisions, Build prototypes to explore applying machine learning to new areas, Build and/or run a machine learning service that operationally improves my product or workflows, Experimentation and iteration to improve existing ML models, Do research that advances the state of the art of machine learning',\n",
       "       ' Build prototypes to explore applying machine learning to new areas, Do research that advances the state of the art of machine learning',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run a machine learning service that operationally improves my product or workflows, Do research that advances the state of the art of machine learning',\n",
       "       ' Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Do research that advances the state of the art of machine learning',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build and/or run a machine learning service that operationally improves my product or workflows, Experimentation and iteration to improve existing ML models',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build prototypes to explore applying machine learning to new areas, Experimentation and iteration to improve existing ML models',\n",
       "       ' Build prototypes to explore applying machine learning to new areas, Build and/or run a machine learning service that operationally improves my product or workflows',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Other',\n",
       "       ' Build prototypes to explore applying machine learning to new areas, Experimentation and iteration to improve existing ML models, Do research that advances the state of the art of machine learning',\n",
       "       ' Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build and/or run a machine learning service that operationally improves my product or workflows, Experimentation and iteration to improve existing ML models',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run a machine learning service that operationally improves my product or workflows, Experimentation and iteration to improve existing ML models, Do research that advances the state of the art of machine learning',\n",
       "       ' Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build prototypes to explore applying machine learning to new areas, Build and/or run a machine learning service that operationally improves my product or workflows, Experimentation and iteration to improve existing ML models, Do research that advances the state of the art of machine learning',\n",
       "       ' Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build and/or run a machine learning service that operationally improves my product or workflows',\n",
       "       'Analyze and understand data to influence product or business decisions, Build prototypes to explore applying machine learning to new areas, Experimentation and iteration to improve existing ML models, Do research that advances the state of the art of machine learning',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build prototypes to explore applying machine learning to new areas, Experimentation and iteration to improve existing ML models, Do research that advances the state of the art of machine learning',\n",
       "       ' Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build prototypes to explore applying machine learning to new areas, Do research that advances the state of the art of machine learning',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build prototypes to explore applying machine learning to new areas, Build and/or run a machine learning service that operationally improves my product or workflows, Do research that advances the state of the art of machine learning',\n",
       "       ' Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build prototypes to explore applying machine learning to new areas, Build and/or run a machine learning service that operationally improves my product or workflows, Experimentation and iteration to improve existing ML models',\n",
       "       'Analyze and understand data to influence product or business decisions, Other',\n",
       "       ' Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build prototypes to explore applying machine learning to new areas, Experimentation and iteration to improve existing ML models, Do research that advances the state of the art of machine learning',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build and/or run a machine learning service that operationally improves my product or workflows, Experimentation and iteration to improve existing ML models, Do research that advances the state of the art of machine learning',\n",
       "       ' Build and/or run a machine learning service that operationally improves my product or workflows, Do research that advances the state of the art of machine learning',\n",
       "       ' Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build prototypes to explore applying machine learning to new areas, Build and/or run a machine learning service that operationally improves my product or workflows, Do research that advances the state of the art of machine learning',\n",
       "       'Analyze and understand data to influence product or business decisions, Experimentation and iteration to improve existing ML models, Other',\n",
       "       ' Build prototypes to explore applying machine learning to new areas, Other',\n",
       "       ' Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Other',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build prototypes to explore applying machine learning to new areas, Build and/or run a machine learning service that operationally improves my product or workflows, Experimentation and iteration to improve existing ML models, Do research that advances the state of the art of machine learning, Other',\n",
       "       ' Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Experimentation and iteration to improve existing ML models, Do research that advances the state of the art of machine learning',\n",
       "       'Analyze and understand data to influence product or business decisions, Do research that advances the state of the art of machine learning, Other',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build and/or run a machine learning service that operationally improves my product or workflows, Other',\n",
       "       ' Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build and/or run a machine learning service that operationally improves my product or workflows, Do research that advances the state of the art of machine learning, Other',\n",
       "       ' Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build and/or run a machine learning service that operationally improves my product or workflows, Experimentation and iteration to improve existing ML models, Do research that advances the state of the art of machine learning',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build and/or run a machine learning service that operationally improves my product or workflows, Experimentation and iteration to improve existing ML models, Other',\n",
       "       'Analyze and understand data to influence product or business decisions, Build prototypes to explore applying machine learning to new areas, Experimentation and iteration to improve existing ML models, Do research that advances the state of the art of machine learning, Other',\n",
       "       ' Build prototypes to explore applying machine learning to new areas, Experimentation and iteration to improve existing ML models, Do research that advances the state of the art of machine learning, Other',\n",
       "       ' Build prototypes to explore applying machine learning to new areas, Experimentation and iteration to improve existing ML models, Other',\n",
       "       ' Build prototypes to explore applying machine learning to new areas, Do research that advances the state of the art of machine learning, Other',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build prototypes to explore applying machine learning to new areas, Build and/or run a machine learning service that operationally improves my product or workflows, Other',\n",
       "       'Analyze and understand data to influence product or business decisions, Build prototypes to explore applying machine learning to new areas, Build and/or run a machine learning service that operationally improves my product or workflows, Do research that advances the state of the art of machine learning, Other',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Do research that advances the state of the art of machine learning, Other',\n",
       "       ' Experimentation and iteration to improve existing ML models, Other',\n",
       "       ' Build prototypes to explore applying machine learning to new areas, Build and/or run a machine learning service that operationally improves my product or workflows, Other',\n",
       "       ' Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build prototypes to explore applying machine learning to new areas, Experimentation and iteration to improve existing ML models, Do research that advances the state of the art of machine learning, Other',\n",
       "       'Analyze and understand data to influence product or business decisions, Build prototypes to explore applying machine learning to new areas, Build and/or run a machine learning service that operationally improves my product or workflows, Experimentation and iteration to improve existing ML models, Other',\n",
       "       'Analyze and understand data to influence product or business decisions, Build prototypes to explore applying machine learning to new areas, Experimentation and iteration to improve existing ML models, Other',\n",
       "       'Analyze and understand data to influence product or business decisions, Experimentation and iteration to improve existing ML models, Do research that advances the state of the art of machine learning, Other',\n",
       "       'Analyze and understand data to influence product or business decisions, Build prototypes to explore applying machine learning to new areas, Other',\n",
       "       ' Build and/or run a machine learning service that operationally improves my product or workflows, Other',\n",
       "       ' Do research that advances the state of the art of machine learning, Other',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run a machine learning service that operationally improves my product or workflows, Other',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build prototypes to explore applying machine learning to new areas, Experimentation and iteration to improve existing ML models, Other',\n",
       "       ' Build and/or run a machine learning service that operationally improves my product or workflows, Do research that advances the state of the art of machine learning, Other',\n",
       "       'Analyze and understand data to influence product or business decisions, Build and/or run the data infrastructure that my business uses for storing; analyzing; and operationalizing data, Build prototypes to explore applying machine learning to new areas, Experimentation and iteration to improve existing ML models, Do research that advances the state of the art of machine learning, Other'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unido['Q24'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jupyter Notebook                                                                                                                   2341\n",
       "Visual Studio Code (VSCode) ,Jupyter Notebook                                                                                      1412\n",
       "Visual Studio Code (VSCode)                                                                                                         939\n",
       "PyCharm ,Jupyter Notebook                                                                                                           820\n",
       "Visual Studio Code (VSCode) ,PyCharm ,Jupyter Notebook                                                                              554\n",
       "                                                                                                                                   ... \n",
       "RStudio ,Visual Studio , Spyder, Vim / Emacs,Jupyter Notebook                                                                         1\n",
       "Jupyter (JupyterLab, Jupyter Notebooks, etc) ,Visual Studio ,Visual Studio Code (VSCode) , Vim / Emacs,MATLAB ,Jupyter Notebook       1\n",
       "Jupyter (JupyterLab, Jupyter Notebooks, etc) ,Visual Studio ,PyCharm , Spyder, Notepad++                                              1\n",
       "RStudio ,Visual Studio , Notepad++, Vim / Emacs                                                                                       1\n",
       "RStudio ,Visual Studio ,Visual Studio Code (VSCode) , Notepad++, Vim / Emacs                                                          1\n",
       "Name: Q9, Length: 1330, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unido['Q9'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_comas2(columna):\n",
    "    try:\n",
    "        patron = r'(\\(.*),(\\s.*),(\\s.*\\))'\n",
    "        return re.sub(patron, r'\\1;\\2;\\3', columna)\n",
    "    except:\n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unido['Q9'] = df_unido['Q9'].apply(separar_comas2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza: Eliminamos columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0\n",
      "level_0\n",
      "index\n",
      "time\n",
      "age\n",
      "gender\n",
      "Q3\n",
      "Q4\n",
      "Q5\n",
      "Q6\n",
      "Q8\n",
      "Q11\n",
      "Q13\n",
      "Q15\n",
      "Q20\n",
      "Q21\n",
      "Q22\n",
      "Q23\n",
      "Q25\n",
      "Q26\n",
      "Q33\n",
      "Q35\n",
      "Q41\n",
      "Q7\n",
      "Q9\n",
      "Q12\n",
      "Q14\n",
      "Q16\n",
      "Q17\n",
      "Q24\n",
      "Q32\n",
      "Q34\n",
      "Q10_Part_1\n",
      "Q10_Part_2\n",
      "Q10_Part_3\n",
      "Q10_Part_4\n",
      "Q10_Part_5\n",
      "Q10_Part_6\n",
      "Q10_Part_7\n",
      "Q10_Part_8\n",
      "Q10_Part_9\n",
      "Q10_Part_10\n",
      "Q10_Part_11\n",
      "Q10_Part_12\n",
      "Q10_Part_13\n",
      "Q10_Part_14\n",
      "Q10_Part_15\n",
      "Q10_Part_16\n",
      "Q10_OTHER\n",
      "Q18_Part_1\n",
      "Q18_Part_2\n",
      "Q18_Part_3\n",
      "Q18_Part_4\n",
      "Q18_Part_5\n",
      "Q18_Part_6\n",
      "Q18_OTHER\n",
      "Q19_Part_1\n",
      "Q19_Part_2\n",
      "Q19_Part_3\n",
      "Q19_Part_4\n",
      "Q19_Part_5\n",
      "Q19_OTHER\n",
      "Q27_A_Part_1\n",
      "Q27_A_Part_2\n",
      "Q27_A_Part_3\n",
      "Q27_A_Part_4\n",
      "Q27_A_Part_5\n",
      "Q27_A_Part_6\n",
      "Q27_A_Part_7\n",
      "Q27_A_Part_8\n",
      "Q27_A_Part_9\n",
      "Q27_A_Part_10\n",
      "Q27_A_Part_11\n",
      "Q27_A_OTHER\n",
      "Q28\n",
      "Q29_A_Part_1\n",
      "Q29_A_Part_2\n",
      "Q29_A_Part_3\n",
      "Q29_A_Part_4\n",
      "Q29_A_OTHER\n",
      "Q30_A_Part_1\n",
      "Q30_A_Part_2\n",
      "Q30_A_Part_3\n",
      "Q30_A_Part_4\n",
      "Q30_A_Part_5\n",
      "Q30_A_Part_6\n",
      "Q30_A_Part_7\n",
      "Q30_A_OTHER\n",
      "Q31_A_Part_1\n",
      "Q31_A_Part_2\n",
      "Q31_A_Part_3\n",
      "Q31_A_Part_4\n",
      "Q31_A_Part_5\n",
      "Q31_A_Part_6\n",
      "Q31_A_Part_7\n",
      "Q31_A_Part_8\n",
      "Q31_A_Part_9\n",
      "Q31_A_OTHER\n",
      "Q36_A_Part_1\n",
      "Q36_A_Part_2\n",
      "Q36_A_Part_3\n",
      "Q36_A_Part_4\n",
      "Q36_A_Part_5\n",
      "Q36_A_Part_6\n",
      "Q36_A_Part_7\n",
      "Q36_A_OTHER\n",
      "Q37_A_Part_1\n",
      "Q37_A_Part_2\n",
      "Q37_A_Part_3\n",
      "Q37_A_Part_4\n",
      "Q37_A_Part_5\n",
      "Q37_A_Part_6\n",
      "Q37_A_Part_7\n",
      "Q37_A_OTHER\n",
      "Q38_A_Part_1\n",
      "Q38_A_Part_2\n",
      "Q38_A_Part_3\n",
      "Q38_A_Part_4\n",
      "Q38_A_Part_5\n",
      "Q38_A_Part_6\n",
      "Q38_A_Part_7\n",
      "Q38_A_Part_8\n",
      "Q38_A_Part_9\n",
      "Q38_A_Part_10\n",
      "Q38_A_Part_11\n",
      "Q38_A_OTHER\n",
      "Q39_Part_1\n",
      "Q39_Part_2\n",
      "Q39_Part_3\n",
      "Q39_Part_4\n",
      "Q39_Part_5\n",
      "Q39_Part_6\n",
      "Q39_Part_7\n",
      "Q39_Part_8\n",
      "Q39_Part_9\n",
      "Q39_OTHER\n",
      "Q40_Part_1\n",
      "Q40_Part_2\n",
      "Q40_Part_3\n",
      "Q40_Part_4\n",
      "Q40_Part_5\n",
      "Q40_Part_6\n",
      "Q40_Part_7\n",
      "Q40_Part_8\n",
      "Q40_Part_9\n",
      "Q40_Part_10\n",
      "Q40_Part_11\n",
      "Q40_OTHER\n",
      "Q42_Part_1\n",
      "Q42_Part_2\n",
      "Q42_Part_3\n",
      "Q42_Part_4\n",
      "Q42_Part_5\n",
      "Q42_Part_6\n",
      "Q42_Part_7\n",
      "Q42_Part_8\n",
      "Q42_Part_9\n",
      "Q42_Part_10\n",
      "Q42_Part_11\n",
      "Q42_OTHER\n",
      "Q27_B_Part_1\n",
      "Q27_B_Part_2\n",
      "Q27_B_Part_3\n",
      "Q27_B_Part_4\n",
      "Q27_B_Part_5\n",
      "Q27_B_Part_6\n",
      "Q27_B_Part_7\n",
      "Q27_B_Part_8\n",
      "Q27_B_Part_9\n",
      "Q27_B_Part_10\n",
      "Q27_B_Part_11\n",
      "Q27_B_OTHER\n",
      "Q29_B_Part_1\n",
      "Q29_B_Part_2\n",
      "Q29_B_Part_3\n",
      "Q29_B_Part_4\n",
      "Q29_B_OTHER\n",
      "Q30_B_Part_1\n",
      "Q30_B_Part_2\n",
      "Q30_B_Part_3\n",
      "Q30_B_Part_4\n",
      "Q30_B_Part_5\n",
      "Q30_B_Part_6\n",
      "Q30_B_Part_7\n",
      "Q30_B_OTHER\n",
      "Q31_B_Part_1\n",
      "Q31_B_Part_2\n",
      "Q31_B_Part_3\n",
      "Q31_B_Part_4\n",
      "Q31_B_Part_5\n",
      "Q31_B_Part_6\n",
      "Q31_B_Part_7\n",
      "Q31_B_Part_8\n",
      "Q31_B_Part_9\n",
      "Q31_B_OTHER\n",
      "Q32_B_Part_1\n",
      "Q32_B_Part_2\n",
      "Q32_B_Part_3\n",
      "Q32_B_Part_4\n",
      "Q32_B_Part_5\n",
      "Q32_B_Part_6\n",
      "Q32_B_Part_7\n",
      "Q32_B_Part_8\n",
      "Q32_B_Part_9\n",
      "Q32_B_Part_10\n",
      "Q32_B_Part_11\n",
      "Q32_B_Part_12\n",
      "Q32_B_Part_13\n",
      "Q32_B_Part_14\n",
      "Q32_B_Part_15\n",
      "Q32_B_Part_16\n",
      "Q32_B_Part_17\n",
      "Q32_B_Part_18\n",
      "Q32_B_Part_19\n",
      "Q32_B_Part_20\n",
      "Q32_B_OTHER\n",
      "Q34_B_Part_1\n",
      "Q34_B_Part_2\n",
      "Q34_B_Part_3\n",
      "Q34_B_Part_4\n",
      "Q34_B_Part_5\n",
      "Q34_B_Part_6\n",
      "Q34_B_Part_7\n",
      "Q34_B_Part_8\n",
      "Q34_B_Part_9\n",
      "Q34_B_Part_10\n",
      "Q34_B_Part_11\n",
      "Q34_B_Part_12\n",
      "Q34_B_Part_13\n",
      "Q34_B_Part_14\n",
      "Q34_B_Part_15\n",
      "Q34_B_Part_16\n",
      "Q34_B_OTHER\n",
      "Q36_B_Part_1\n",
      "Q36_B_Part_2\n",
      "Q36_B_Part_3\n",
      "Q36_B_Part_4\n",
      "Q36_B_Part_5\n",
      "Q36_B_Part_6\n",
      "Q36_B_Part_7\n",
      "Q36_B_OTHER\n",
      "Q37_B_Part_1\n",
      "Q37_B_Part_2\n",
      "Q37_B_Part_3\n",
      "Q37_B_Part_4\n",
      "Q37_B_Part_5\n",
      "Q37_B_Part_6\n",
      "Q37_B_Part_7\n",
      "Q37_B_OTHER\n",
      "Q38_B_Part_1\n",
      "Q38_B_Part_2\n",
      "Q38_B_Part_3\n",
      "Q38_B_Part_4\n",
      "Q38_B_Part_5\n",
      "Q38_B_Part_6\n",
      "Q38_B_Part_7\n",
      "Q38_B_Part_8\n",
      "Q38_B_Part_9\n",
      "Q38_B_Part_10\n",
      "Q38_B_Part_11\n",
      "Q38_B_OTHER\n"
     ]
    }
   ],
   "source": [
    "for col in df_unido.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_etiqueta (dataframe, *lista_columna):\n",
    "    #función para eliminar las columnas en las que no nos vamos a centrar en el estudio, por etiqueta/nombre de columna, \n",
    "    #los parámetros que coge son dataframe y una lista de nombres de las columnas de ese dataframe\n",
    "    for columna in dataframe.columns:\n",
    "        for elemento  in lista_columna:\n",
    "            if elemento == columna:\n",
    "                #esta función itera por nuestra lista_columna (el arg) y comprueba si el elemento (la etiqueta a eliminar)\n",
    "                # se encuentra en cada columna, y, de ser así, la eliminará usando el método .drop()\n",
    "                dataframe.drop([columna],axis = 1, inplace = True)\n",
    "    return dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'index', 'age', 'gender', 'Q3', 'Q5', 'Q6', 'Q8', 'Q15',\n",
       "       'Q22',\n",
       "       ...\n",
       "       'Q38_B_Part_3', 'Q38_B_Part_4', 'Q38_B_Part_5', 'Q38_B_Part_6',\n",
       "       'Q38_B_Part_7', 'Q38_B_Part_8', 'Q38_B_Part_9', 'Q38_B_Part_10',\n",
       "       'Q38_B_Part_11', 'Q38_B_OTHER'],\n",
       "      dtype='object', length=254)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eliminamos columnas sueltas\n",
    "eliminar_etiqueta(df_unido, *['level_0', 'time', 'Q4', 'Q11', 'Q13', 'Q20', 'Q21'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0\n",
      "index\n",
      "age\n",
      "gender\n",
      "Q3\n",
      "Q5\n",
      "Q6\n",
      "Q8\n",
      "Q15\n",
      "Q22\n",
      "Q23\n",
      "Q25\n",
      "Q26\n",
      "Q33\n",
      "Q35\n",
      "Q41\n",
      "Q7\n",
      "Q9\n",
      "Q12\n",
      "Q14\n",
      "Q16\n",
      "Q17\n",
      "Q24\n",
      "Q32\n",
      "Q34\n",
      "Q10_Part_1\n",
      "Q10_Part_2\n",
      "Q10_Part_3\n",
      "Q10_Part_4\n",
      "Q10_Part_5\n",
      "Q10_Part_6\n",
      "Q10_Part_7\n",
      "Q10_Part_8\n",
      "Q10_Part_9\n",
      "Q10_Part_10\n",
      "Q10_Part_11\n",
      "Q10_Part_12\n",
      "Q10_Part_13\n",
      "Q10_Part_14\n",
      "Q10_Part_15\n",
      "Q10_Part_16\n",
      "Q10_OTHER\n",
      "Q18_Part_1\n",
      "Q18_Part_2\n",
      "Q18_Part_3\n",
      "Q18_Part_4\n",
      "Q18_Part_5\n",
      "Q18_Part_6\n",
      "Q18_OTHER\n",
      "Q19_Part_1\n",
      "Q19_Part_2\n",
      "Q19_Part_3\n",
      "Q19_Part_4\n",
      "Q19_Part_5\n",
      "Q19_OTHER\n",
      "Q27_A_Part_1\n",
      "Q27_A_Part_2\n",
      "Q27_A_Part_3\n",
      "Q27_A_Part_4\n",
      "Q27_A_Part_5\n",
      "Q27_A_Part_6\n",
      "Q27_A_Part_7\n",
      "Q27_A_Part_8\n",
      "Q27_A_Part_9\n",
      "Q27_A_Part_10\n",
      "Q27_A_Part_11\n",
      "Q27_A_OTHER\n",
      "Q28\n",
      "Q29_A_Part_1\n",
      "Q29_A_Part_2\n",
      "Q29_A_Part_3\n",
      "Q29_A_Part_4\n",
      "Q29_A_OTHER\n",
      "Q30_A_Part_1\n",
      "Q30_A_Part_2\n",
      "Q30_A_Part_3\n",
      "Q30_A_Part_4\n",
      "Q30_A_Part_5\n",
      "Q30_A_Part_6\n",
      "Q30_A_Part_7\n",
      "Q30_A_OTHER\n",
      "Q31_A_Part_1\n",
      "Q31_A_Part_2\n",
      "Q31_A_Part_3\n",
      "Q31_A_Part_4\n",
      "Q31_A_Part_5\n",
      "Q31_A_Part_6\n",
      "Q31_A_Part_7\n",
      "Q31_A_Part_8\n",
      "Q31_A_Part_9\n",
      "Q31_A_OTHER\n",
      "Q36_A_Part_1\n",
      "Q36_A_Part_2\n",
      "Q36_A_Part_3\n",
      "Q36_A_Part_4\n",
      "Q36_A_Part_5\n",
      "Q36_A_Part_6\n",
      "Q36_A_Part_7\n",
      "Q36_A_OTHER\n",
      "Q37_A_Part_1\n",
      "Q37_A_Part_2\n",
      "Q37_A_Part_3\n",
      "Q37_A_Part_4\n",
      "Q37_A_Part_5\n",
      "Q37_A_Part_6\n",
      "Q37_A_Part_7\n",
      "Q37_A_OTHER\n",
      "Q38_A_Part_1\n",
      "Q38_A_Part_2\n",
      "Q38_A_Part_3\n",
      "Q38_A_Part_4\n",
      "Q38_A_Part_5\n",
      "Q38_A_Part_6\n",
      "Q38_A_Part_7\n",
      "Q38_A_Part_8\n",
      "Q38_A_Part_9\n",
      "Q38_A_Part_10\n",
      "Q38_A_Part_11\n",
      "Q38_A_OTHER\n",
      "Q39_Part_1\n",
      "Q39_Part_2\n",
      "Q39_Part_3\n",
      "Q39_Part_4\n",
      "Q39_Part_5\n",
      "Q39_Part_6\n",
      "Q39_Part_7\n",
      "Q39_Part_8\n",
      "Q39_Part_9\n",
      "Q39_OTHER\n",
      "Q40_Part_1\n",
      "Q40_Part_2\n",
      "Q40_Part_3\n",
      "Q40_Part_4\n",
      "Q40_Part_5\n",
      "Q40_Part_6\n",
      "Q40_Part_7\n",
      "Q40_Part_8\n",
      "Q40_Part_9\n",
      "Q40_Part_10\n",
      "Q40_Part_11\n",
      "Q40_OTHER\n",
      "Q42_Part_1\n",
      "Q42_Part_2\n",
      "Q42_Part_3\n",
      "Q42_Part_4\n",
      "Q42_Part_5\n",
      "Q42_Part_6\n",
      "Q42_Part_7\n",
      "Q42_Part_8\n",
      "Q42_Part_9\n",
      "Q42_Part_10\n",
      "Q42_Part_11\n",
      "Q42_OTHER\n",
      "Q27_B_Part_1\n",
      "Q27_B_Part_2\n",
      "Q27_B_Part_3\n",
      "Q27_B_Part_4\n",
      "Q27_B_Part_5\n",
      "Q27_B_Part_6\n",
      "Q27_B_Part_7\n",
      "Q27_B_Part_8\n",
      "Q27_B_Part_9\n",
      "Q27_B_Part_10\n",
      "Q27_B_Part_11\n",
      "Q27_B_OTHER\n",
      "Q29_B_Part_1\n",
      "Q29_B_Part_2\n",
      "Q29_B_Part_3\n",
      "Q29_B_Part_4\n",
      "Q29_B_OTHER\n",
      "Q30_B_Part_1\n",
      "Q30_B_Part_2\n",
      "Q30_B_Part_3\n",
      "Q30_B_Part_4\n",
      "Q30_B_Part_5\n",
      "Q30_B_Part_6\n",
      "Q30_B_Part_7\n",
      "Q30_B_OTHER\n",
      "Q31_B_Part_1\n",
      "Q31_B_Part_2\n",
      "Q31_B_Part_3\n",
      "Q31_B_Part_4\n",
      "Q31_B_Part_5\n",
      "Q31_B_Part_6\n",
      "Q31_B_Part_7\n",
      "Q31_B_Part_8\n",
      "Q31_B_Part_9\n",
      "Q31_B_OTHER\n",
      "Q32_B_Part_1\n",
      "Q32_B_Part_2\n",
      "Q32_B_Part_3\n",
      "Q32_B_Part_4\n",
      "Q32_B_Part_5\n",
      "Q32_B_Part_6\n",
      "Q32_B_Part_7\n",
      "Q32_B_Part_8\n",
      "Q32_B_Part_9\n",
      "Q32_B_Part_10\n",
      "Q32_B_Part_11\n",
      "Q32_B_Part_12\n",
      "Q32_B_Part_13\n",
      "Q32_B_Part_14\n",
      "Q32_B_Part_15\n",
      "Q32_B_Part_16\n",
      "Q32_B_Part_17\n",
      "Q32_B_Part_18\n",
      "Q32_B_Part_19\n",
      "Q32_B_Part_20\n",
      "Q32_B_OTHER\n",
      "Q34_B_Part_1\n",
      "Q34_B_Part_2\n",
      "Q34_B_Part_3\n",
      "Q34_B_Part_4\n",
      "Q34_B_Part_5\n",
      "Q34_B_Part_6\n",
      "Q34_B_Part_7\n",
      "Q34_B_Part_8\n",
      "Q34_B_Part_9\n",
      "Q34_B_Part_10\n",
      "Q34_B_Part_11\n",
      "Q34_B_Part_12\n",
      "Q34_B_Part_13\n",
      "Q34_B_Part_14\n",
      "Q34_B_Part_15\n",
      "Q34_B_Part_16\n",
      "Q34_B_OTHER\n",
      "Q36_B_Part_1\n",
      "Q36_B_Part_2\n",
      "Q36_B_Part_3\n",
      "Q36_B_Part_4\n",
      "Q36_B_Part_5\n",
      "Q36_B_Part_6\n",
      "Q36_B_Part_7\n",
      "Q36_B_OTHER\n",
      "Q37_B_Part_1\n",
      "Q37_B_Part_2\n",
      "Q37_B_Part_3\n",
      "Q37_B_Part_4\n",
      "Q37_B_Part_5\n",
      "Q37_B_Part_6\n",
      "Q37_B_Part_7\n",
      "Q37_B_OTHER\n",
      "Q38_B_Part_1\n",
      "Q38_B_Part_2\n",
      "Q38_B_Part_3\n",
      "Q38_B_Part_4\n",
      "Q38_B_Part_5\n",
      "Q38_B_Part_6\n",
      "Q38_B_Part_7\n",
      "Q38_B_Part_8\n",
      "Q38_B_Part_9\n",
      "Q38_B_Part_10\n",
      "Q38_B_Part_11\n",
      "Q38_B_OTHER\n"
     ]
    }
   ],
   "source": [
    "for col in df_unido.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# función para eliminar las columnas en las que no nos vamos a centrar en el estudio, por rango \n",
    "def eliminar_indices (dataframe, columna1, columna2):\n",
    "    #creamos un diccionario de los índices por columna de nuestro df\n",
    "    diccionario = {}\n",
    "    #los nombres de las columnas serán nuestras keys para poder acceder a los índices usando los nombres de las columnas (los parámetros)\n",
    "    for indice, col in enumerate(df_unido.columns):\n",
    "        diccionario.update({col: indice})\n",
    "    print(diccionario)\n",
    "    #usamos el diccionario para obtener los índices en el rango \n",
    "    if columna1 in diccionario:\n",
    "        indice1 = diccionario.get(columna1)\n",
    "    else: \n",
    "        print('Columna1 no está en el diccionario')\n",
    "    if columna2 in diccionario:\n",
    "    #usamos el +1 para poder acceder al último índice\n",
    "        indice2 = diccionario.get(columna2) + 1\n",
    "    else: \n",
    "        print('Columna2 no está en el diccionario')\n",
    "        #usamos los índices para borrar el rango de columnas y así eliminiar varias a la vez\n",
    "    for elemento in dataframe.columns[indice1:indice2]:    \n",
    "        dataframe.drop([elemento],axis = 1, inplace = True)\n",
    "    return dataframe.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la función nos vamos deshaciendo en rangos de las columnas que no nos aportan información con valor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Unnamed: 0': 0, 'index': 1, 'age': 2, 'gender': 3, 'Q3': 4, 'Q5': 5, 'Q6': 6, 'Q8': 7, 'Q15': 8, 'Q22': 9, 'Q23': 10, 'Q25': 11, 'Q26': 12, 'Q33': 13, 'Q35': 14, 'Q41': 15, 'Q7': 16, 'Q9': 17, 'Q12': 18, 'Q14': 19, 'Q16': 20, 'Q17': 21, 'Q24': 22, 'Q32': 23, 'Q34': 24, 'Q10_Part_1': 25, 'Q10_Part_2': 26, 'Q10_Part_3': 27, 'Q10_Part_4': 28, 'Q10_Part_5': 29, 'Q10_Part_6': 30, 'Q10_Part_7': 31, 'Q10_Part_8': 32, 'Q10_Part_9': 33, 'Q10_Part_10': 34, 'Q10_Part_11': 35, 'Q10_Part_12': 36, 'Q10_Part_13': 37, 'Q10_Part_14': 38, 'Q10_Part_15': 39, 'Q10_Part_16': 40, 'Q10_OTHER': 41, 'Q18_Part_1': 42, 'Q18_Part_2': 43, 'Q18_Part_3': 44, 'Q18_Part_4': 45, 'Q18_Part_5': 46, 'Q18_Part_6': 47, 'Q18_OTHER': 48, 'Q19_Part_1': 49, 'Q19_Part_2': 50, 'Q19_Part_3': 51, 'Q19_Part_4': 52, 'Q19_Part_5': 53, 'Q19_OTHER': 54, 'Q27_A_Part_1': 55, 'Q27_A_Part_2': 56, 'Q27_A_Part_3': 57, 'Q27_A_Part_4': 58, 'Q27_A_Part_5': 59, 'Q27_A_Part_6': 60, 'Q27_A_Part_7': 61, 'Q27_A_Part_8': 62, 'Q27_A_Part_9': 63, 'Q27_A_Part_10': 64, 'Q27_A_Part_11': 65, 'Q27_A_OTHER': 66, 'Q28': 67, 'Q29_A_Part_1': 68, 'Q29_A_Part_2': 69, 'Q29_A_Part_3': 70, 'Q29_A_Part_4': 71, 'Q29_A_OTHER': 72, 'Q30_A_Part_1': 73, 'Q30_A_Part_2': 74, 'Q30_A_Part_3': 75, 'Q30_A_Part_4': 76, 'Q30_A_Part_5': 77, 'Q30_A_Part_6': 78, 'Q30_A_Part_7': 79, 'Q30_A_OTHER': 80, 'Q31_A_Part_1': 81, 'Q31_A_Part_2': 82, 'Q31_A_Part_3': 83, 'Q31_A_Part_4': 84, 'Q31_A_Part_5': 85, 'Q31_A_Part_6': 86, 'Q31_A_Part_7': 87, 'Q31_A_Part_8': 88, 'Q31_A_Part_9': 89, 'Q31_A_OTHER': 90, 'Q36_A_Part_1': 91, 'Q36_A_Part_2': 92, 'Q36_A_Part_3': 93, 'Q36_A_Part_4': 94, 'Q36_A_Part_5': 95, 'Q36_A_Part_6': 96, 'Q36_A_Part_7': 97, 'Q36_A_OTHER': 98, 'Q37_A_Part_1': 99, 'Q37_A_Part_2': 100, 'Q37_A_Part_3': 101, 'Q37_A_Part_4': 102, 'Q37_A_Part_5': 103, 'Q37_A_Part_6': 104, 'Q37_A_Part_7': 105, 'Q37_A_OTHER': 106, 'Q38_A_Part_1': 107, 'Q38_A_Part_2': 108, 'Q38_A_Part_3': 109, 'Q38_A_Part_4': 110, 'Q38_A_Part_5': 111, 'Q38_A_Part_6': 112, 'Q38_A_Part_7': 113, 'Q38_A_Part_8': 114, 'Q38_A_Part_9': 115, 'Q38_A_Part_10': 116, 'Q38_A_Part_11': 117, 'Q38_A_OTHER': 118, 'Q39_Part_1': 119, 'Q39_Part_2': 120, 'Q39_Part_3': 121, 'Q39_Part_4': 122, 'Q39_Part_5': 123, 'Q39_Part_6': 124, 'Q39_Part_7': 125, 'Q39_Part_8': 126, 'Q39_Part_9': 127, 'Q39_OTHER': 128, 'Q40_Part_1': 129, 'Q40_Part_2': 130, 'Q40_Part_3': 131, 'Q40_Part_4': 132, 'Q40_Part_5': 133, 'Q40_Part_6': 134, 'Q40_Part_7': 135, 'Q40_Part_8': 136, 'Q40_Part_9': 137, 'Q40_Part_10': 138, 'Q40_Part_11': 139, 'Q40_OTHER': 140, 'Q42_Part_1': 141, 'Q42_Part_2': 142, 'Q42_Part_3': 143, 'Q42_Part_4': 144, 'Q42_Part_5': 145, 'Q42_Part_6': 146, 'Q42_Part_7': 147, 'Q42_Part_8': 148, 'Q42_Part_9': 149, 'Q42_Part_10': 150, 'Q42_Part_11': 151, 'Q42_OTHER': 152, 'Q27_B_Part_1': 153, 'Q27_B_Part_2': 154, 'Q27_B_Part_3': 155, 'Q27_B_Part_4': 156, 'Q27_B_Part_5': 157, 'Q27_B_Part_6': 158, 'Q27_B_Part_7': 159, 'Q27_B_Part_8': 160, 'Q27_B_Part_9': 161, 'Q27_B_Part_10': 162, 'Q27_B_Part_11': 163, 'Q27_B_OTHER': 164, 'Q29_B_Part_1': 165, 'Q29_B_Part_2': 166, 'Q29_B_Part_3': 167, 'Q29_B_Part_4': 168, 'Q29_B_OTHER': 169, 'Q30_B_Part_1': 170, 'Q30_B_Part_2': 171, 'Q30_B_Part_3': 172, 'Q30_B_Part_4': 173, 'Q30_B_Part_5': 174, 'Q30_B_Part_6': 175, 'Q30_B_Part_7': 176, 'Q30_B_OTHER': 177, 'Q31_B_Part_1': 178, 'Q31_B_Part_2': 179, 'Q31_B_Part_3': 180, 'Q31_B_Part_4': 181, 'Q31_B_Part_5': 182, 'Q31_B_Part_6': 183, 'Q31_B_Part_7': 184, 'Q31_B_Part_8': 185, 'Q31_B_Part_9': 186, 'Q31_B_OTHER': 187, 'Q32_B_Part_1': 188, 'Q32_B_Part_2': 189, 'Q32_B_Part_3': 190, 'Q32_B_Part_4': 191, 'Q32_B_Part_5': 192, 'Q32_B_Part_6': 193, 'Q32_B_Part_7': 194, 'Q32_B_Part_8': 195, 'Q32_B_Part_9': 196, 'Q32_B_Part_10': 197, 'Q32_B_Part_11': 198, 'Q32_B_Part_12': 199, 'Q32_B_Part_13': 200, 'Q32_B_Part_14': 201, 'Q32_B_Part_15': 202, 'Q32_B_Part_16': 203, 'Q32_B_Part_17': 204, 'Q32_B_Part_18': 205, 'Q32_B_Part_19': 206, 'Q32_B_Part_20': 207, 'Q32_B_OTHER': 208, 'Q34_B_Part_1': 209, 'Q34_B_Part_2': 210, 'Q34_B_Part_3': 211, 'Q34_B_Part_4': 212, 'Q34_B_Part_5': 213, 'Q34_B_Part_6': 214, 'Q34_B_Part_7': 215, 'Q34_B_Part_8': 216, 'Q34_B_Part_9': 217, 'Q34_B_Part_10': 218, 'Q34_B_Part_11': 219, 'Q34_B_Part_12': 220, 'Q34_B_Part_13': 221, 'Q34_B_Part_14': 222, 'Q34_B_Part_15': 223, 'Q34_B_Part_16': 224, 'Q34_B_OTHER': 225, 'Q36_B_Part_1': 226, 'Q36_B_Part_2': 227, 'Q36_B_Part_3': 228, 'Q36_B_Part_4': 229, 'Q36_B_Part_5': 230, 'Q36_B_Part_6': 231, 'Q36_B_Part_7': 232, 'Q36_B_OTHER': 233, 'Q37_B_Part_1': 234, 'Q37_B_Part_2': 235, 'Q37_B_Part_3': 236, 'Q37_B_Part_4': 237, 'Q37_B_Part_5': 238, 'Q37_B_Part_6': 239, 'Q37_B_Part_7': 240, 'Q37_B_OTHER': 241, 'Q38_B_Part_1': 242, 'Q38_B_Part_2': 243, 'Q38_B_Part_3': 244, 'Q38_B_Part_4': 245, 'Q38_B_Part_5': 246, 'Q38_B_Part_6': 247, 'Q38_B_Part_7': 248, 'Q38_B_Part_8': 249, 'Q38_B_Part_9': 250, 'Q38_B_Part_10': 251, 'Q38_B_Part_11': 252, 'Q38_B_OTHER': 253}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'index', 'age', 'gender', 'Q3', 'Q5', 'Q6', 'Q8', 'Q15',\n",
       "       'Q22',\n",
       "       ...\n",
       "       'Q38_B_Part_3', 'Q38_B_Part_4', 'Q38_B_Part_5', 'Q38_B_Part_6',\n",
       "       'Q38_B_Part_7', 'Q38_B_Part_8', 'Q38_B_Part_9', 'Q38_B_Part_10',\n",
       "       'Q38_B_Part_11', 'Q38_B_OTHER'],\n",
       "      dtype='object', length=250)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eliminar_indices(df_unido, 'Q12', 'Q17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Unnamed: 0': 0, 'index': 1, 'age': 2, 'gender': 3, 'Q3': 4, 'Q5': 5, 'Q6': 6, 'Q8': 7, 'Q15': 8, 'Q22': 9, 'Q23': 10, 'Q25': 11, 'Q26': 12, 'Q33': 13, 'Q35': 14, 'Q41': 15, 'Q7': 16, 'Q9': 17, 'Q24': 18, 'Q32': 19, 'Q34': 20, 'Q10_Part_1': 21, 'Q10_Part_2': 22, 'Q10_Part_3': 23, 'Q10_Part_4': 24, 'Q10_Part_5': 25, 'Q10_Part_6': 26, 'Q10_Part_7': 27, 'Q10_Part_8': 28, 'Q10_Part_9': 29, 'Q10_Part_10': 30, 'Q10_Part_11': 31, 'Q10_Part_12': 32, 'Q10_Part_13': 33, 'Q10_Part_14': 34, 'Q10_Part_15': 35, 'Q10_Part_16': 36, 'Q10_OTHER': 37, 'Q18_Part_1': 38, 'Q18_Part_2': 39, 'Q18_Part_3': 40, 'Q18_Part_4': 41, 'Q18_Part_5': 42, 'Q18_Part_6': 43, 'Q18_OTHER': 44, 'Q19_Part_1': 45, 'Q19_Part_2': 46, 'Q19_Part_3': 47, 'Q19_Part_4': 48, 'Q19_Part_5': 49, 'Q19_OTHER': 50, 'Q27_A_Part_1': 51, 'Q27_A_Part_2': 52, 'Q27_A_Part_3': 53, 'Q27_A_Part_4': 54, 'Q27_A_Part_5': 55, 'Q27_A_Part_6': 56, 'Q27_A_Part_7': 57, 'Q27_A_Part_8': 58, 'Q27_A_Part_9': 59, 'Q27_A_Part_10': 60, 'Q27_A_Part_11': 61, 'Q27_A_OTHER': 62, 'Q28': 63, 'Q29_A_Part_1': 64, 'Q29_A_Part_2': 65, 'Q29_A_Part_3': 66, 'Q29_A_Part_4': 67, 'Q29_A_OTHER': 68, 'Q30_A_Part_1': 69, 'Q30_A_Part_2': 70, 'Q30_A_Part_3': 71, 'Q30_A_Part_4': 72, 'Q30_A_Part_5': 73, 'Q30_A_Part_6': 74, 'Q30_A_Part_7': 75, 'Q30_A_OTHER': 76, 'Q31_A_Part_1': 77, 'Q31_A_Part_2': 78, 'Q31_A_Part_3': 79, 'Q31_A_Part_4': 80, 'Q31_A_Part_5': 81, 'Q31_A_Part_6': 82, 'Q31_A_Part_7': 83, 'Q31_A_Part_8': 84, 'Q31_A_Part_9': 85, 'Q31_A_OTHER': 86, 'Q36_A_Part_1': 87, 'Q36_A_Part_2': 88, 'Q36_A_Part_3': 89, 'Q36_A_Part_4': 90, 'Q36_A_Part_5': 91, 'Q36_A_Part_6': 92, 'Q36_A_Part_7': 93, 'Q36_A_OTHER': 94, 'Q37_A_Part_1': 95, 'Q37_A_Part_2': 96, 'Q37_A_Part_3': 97, 'Q37_A_Part_4': 98, 'Q37_A_Part_5': 99, 'Q37_A_Part_6': 100, 'Q37_A_Part_7': 101, 'Q37_A_OTHER': 102, 'Q38_A_Part_1': 103, 'Q38_A_Part_2': 104, 'Q38_A_Part_3': 105, 'Q38_A_Part_4': 106, 'Q38_A_Part_5': 107, 'Q38_A_Part_6': 108, 'Q38_A_Part_7': 109, 'Q38_A_Part_8': 110, 'Q38_A_Part_9': 111, 'Q38_A_Part_10': 112, 'Q38_A_Part_11': 113, 'Q38_A_OTHER': 114, 'Q39_Part_1': 115, 'Q39_Part_2': 116, 'Q39_Part_3': 117, 'Q39_Part_4': 118, 'Q39_Part_5': 119, 'Q39_Part_6': 120, 'Q39_Part_7': 121, 'Q39_Part_8': 122, 'Q39_Part_9': 123, 'Q39_OTHER': 124, 'Q40_Part_1': 125, 'Q40_Part_2': 126, 'Q40_Part_3': 127, 'Q40_Part_4': 128, 'Q40_Part_5': 129, 'Q40_Part_6': 130, 'Q40_Part_7': 131, 'Q40_Part_8': 132, 'Q40_Part_9': 133, 'Q40_Part_10': 134, 'Q40_Part_11': 135, 'Q40_OTHER': 136, 'Q42_Part_1': 137, 'Q42_Part_2': 138, 'Q42_Part_3': 139, 'Q42_Part_4': 140, 'Q42_Part_5': 141, 'Q42_Part_6': 142, 'Q42_Part_7': 143, 'Q42_Part_8': 144, 'Q42_Part_9': 145, 'Q42_Part_10': 146, 'Q42_Part_11': 147, 'Q42_OTHER': 148, 'Q27_B_Part_1': 149, 'Q27_B_Part_2': 150, 'Q27_B_Part_3': 151, 'Q27_B_Part_4': 152, 'Q27_B_Part_5': 153, 'Q27_B_Part_6': 154, 'Q27_B_Part_7': 155, 'Q27_B_Part_8': 156, 'Q27_B_Part_9': 157, 'Q27_B_Part_10': 158, 'Q27_B_Part_11': 159, 'Q27_B_OTHER': 160, 'Q29_B_Part_1': 161, 'Q29_B_Part_2': 162, 'Q29_B_Part_3': 163, 'Q29_B_Part_4': 164, 'Q29_B_OTHER': 165, 'Q30_B_Part_1': 166, 'Q30_B_Part_2': 167, 'Q30_B_Part_3': 168, 'Q30_B_Part_4': 169, 'Q30_B_Part_5': 170, 'Q30_B_Part_6': 171, 'Q30_B_Part_7': 172, 'Q30_B_OTHER': 173, 'Q31_B_Part_1': 174, 'Q31_B_Part_2': 175, 'Q31_B_Part_3': 176, 'Q31_B_Part_4': 177, 'Q31_B_Part_5': 178, 'Q31_B_Part_6': 179, 'Q31_B_Part_7': 180, 'Q31_B_Part_8': 181, 'Q31_B_Part_9': 182, 'Q31_B_OTHER': 183, 'Q32_B_Part_1': 184, 'Q32_B_Part_2': 185, 'Q32_B_Part_3': 186, 'Q32_B_Part_4': 187, 'Q32_B_Part_5': 188, 'Q32_B_Part_6': 189, 'Q32_B_Part_7': 190, 'Q32_B_Part_8': 191, 'Q32_B_Part_9': 192, 'Q32_B_Part_10': 193, 'Q32_B_Part_11': 194, 'Q32_B_Part_12': 195, 'Q32_B_Part_13': 196, 'Q32_B_Part_14': 197, 'Q32_B_Part_15': 198, 'Q32_B_Part_16': 199, 'Q32_B_Part_17': 200, 'Q32_B_Part_18': 201, 'Q32_B_Part_19': 202, 'Q32_B_Part_20': 203, 'Q32_B_OTHER': 204, 'Q34_B_Part_1': 205, 'Q34_B_Part_2': 206, 'Q34_B_Part_3': 207, 'Q34_B_Part_4': 208, 'Q34_B_Part_5': 209, 'Q34_B_Part_6': 210, 'Q34_B_Part_7': 211, 'Q34_B_Part_8': 212, 'Q34_B_Part_9': 213, 'Q34_B_Part_10': 214, 'Q34_B_Part_11': 215, 'Q34_B_Part_12': 216, 'Q34_B_Part_13': 217, 'Q34_B_Part_14': 218, 'Q34_B_Part_15': 219, 'Q34_B_Part_16': 220, 'Q34_B_OTHER': 221, 'Q36_B_Part_1': 222, 'Q36_B_Part_2': 223, 'Q36_B_Part_3': 224, 'Q36_B_Part_4': 225, 'Q36_B_Part_5': 226, 'Q36_B_Part_6': 227, 'Q36_B_Part_7': 228, 'Q36_B_OTHER': 229, 'Q37_B_Part_1': 230, 'Q37_B_Part_2': 231, 'Q37_B_Part_3': 232, 'Q37_B_Part_4': 233, 'Q37_B_Part_5': 234, 'Q37_B_Part_6': 235, 'Q37_B_Part_7': 236, 'Q37_B_OTHER': 237, 'Q38_B_Part_1': 238, 'Q38_B_Part_2': 239, 'Q38_B_Part_3': 240, 'Q38_B_Part_4': 241, 'Q38_B_Part_5': 242, 'Q38_B_Part_6': 243, 'Q38_B_Part_7': 244, 'Q38_B_Part_8': 245, 'Q38_B_Part_9': 246, 'Q38_B_Part_10': 247, 'Q38_B_Part_11': 248, 'Q38_B_OTHER': 249}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'index', 'age', 'gender', 'Q3', 'Q5', 'Q6', 'Q8', 'Q15',\n",
       "       'Q22',\n",
       "       ...\n",
       "       'Q38_B_Part_3', 'Q38_B_Part_4', 'Q38_B_Part_5', 'Q38_B_Part_6',\n",
       "       'Q38_B_Part_7', 'Q38_B_Part_8', 'Q38_B_Part_9', 'Q38_B_Part_10',\n",
       "       'Q38_B_Part_11', 'Q38_B_OTHER'],\n",
       "      dtype='object', length=245)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eliminar_indices(df_unido, 'Q23', 'Q35')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Unnamed: 0': 0, 'index': 1, 'age': 2, 'gender': 3, 'Q3': 4, 'Q5': 5, 'Q6': 6, 'Q8': 7, 'Q15': 8, 'Q22': 9, 'Q41': 10, 'Q7': 11, 'Q9': 12, 'Q24': 13, 'Q32': 14, 'Q34': 15, 'Q10_Part_1': 16, 'Q10_Part_2': 17, 'Q10_Part_3': 18, 'Q10_Part_4': 19, 'Q10_Part_5': 20, 'Q10_Part_6': 21, 'Q10_Part_7': 22, 'Q10_Part_8': 23, 'Q10_Part_9': 24, 'Q10_Part_10': 25, 'Q10_Part_11': 26, 'Q10_Part_12': 27, 'Q10_Part_13': 28, 'Q10_Part_14': 29, 'Q10_Part_15': 30, 'Q10_Part_16': 31, 'Q10_OTHER': 32, 'Q18_Part_1': 33, 'Q18_Part_2': 34, 'Q18_Part_3': 35, 'Q18_Part_4': 36, 'Q18_Part_5': 37, 'Q18_Part_6': 38, 'Q18_OTHER': 39, 'Q19_Part_1': 40, 'Q19_Part_2': 41, 'Q19_Part_3': 42, 'Q19_Part_4': 43, 'Q19_Part_5': 44, 'Q19_OTHER': 45, 'Q27_A_Part_1': 46, 'Q27_A_Part_2': 47, 'Q27_A_Part_3': 48, 'Q27_A_Part_4': 49, 'Q27_A_Part_5': 50, 'Q27_A_Part_6': 51, 'Q27_A_Part_7': 52, 'Q27_A_Part_8': 53, 'Q27_A_Part_9': 54, 'Q27_A_Part_10': 55, 'Q27_A_Part_11': 56, 'Q27_A_OTHER': 57, 'Q28': 58, 'Q29_A_Part_1': 59, 'Q29_A_Part_2': 60, 'Q29_A_Part_3': 61, 'Q29_A_Part_4': 62, 'Q29_A_OTHER': 63, 'Q30_A_Part_1': 64, 'Q30_A_Part_2': 65, 'Q30_A_Part_3': 66, 'Q30_A_Part_4': 67, 'Q30_A_Part_5': 68, 'Q30_A_Part_6': 69, 'Q30_A_Part_7': 70, 'Q30_A_OTHER': 71, 'Q31_A_Part_1': 72, 'Q31_A_Part_2': 73, 'Q31_A_Part_3': 74, 'Q31_A_Part_4': 75, 'Q31_A_Part_5': 76, 'Q31_A_Part_6': 77, 'Q31_A_Part_7': 78, 'Q31_A_Part_8': 79, 'Q31_A_Part_9': 80, 'Q31_A_OTHER': 81, 'Q36_A_Part_1': 82, 'Q36_A_Part_2': 83, 'Q36_A_Part_3': 84, 'Q36_A_Part_4': 85, 'Q36_A_Part_5': 86, 'Q36_A_Part_6': 87, 'Q36_A_Part_7': 88, 'Q36_A_OTHER': 89, 'Q37_A_Part_1': 90, 'Q37_A_Part_2': 91, 'Q37_A_Part_3': 92, 'Q37_A_Part_4': 93, 'Q37_A_Part_5': 94, 'Q37_A_Part_6': 95, 'Q37_A_Part_7': 96, 'Q37_A_OTHER': 97, 'Q38_A_Part_1': 98, 'Q38_A_Part_2': 99, 'Q38_A_Part_3': 100, 'Q38_A_Part_4': 101, 'Q38_A_Part_5': 102, 'Q38_A_Part_6': 103, 'Q38_A_Part_7': 104, 'Q38_A_Part_8': 105, 'Q38_A_Part_9': 106, 'Q38_A_Part_10': 107, 'Q38_A_Part_11': 108, 'Q38_A_OTHER': 109, 'Q39_Part_1': 110, 'Q39_Part_2': 111, 'Q39_Part_3': 112, 'Q39_Part_4': 113, 'Q39_Part_5': 114, 'Q39_Part_6': 115, 'Q39_Part_7': 116, 'Q39_Part_8': 117, 'Q39_Part_9': 118, 'Q39_OTHER': 119, 'Q40_Part_1': 120, 'Q40_Part_2': 121, 'Q40_Part_3': 122, 'Q40_Part_4': 123, 'Q40_Part_5': 124, 'Q40_Part_6': 125, 'Q40_Part_7': 126, 'Q40_Part_8': 127, 'Q40_Part_9': 128, 'Q40_Part_10': 129, 'Q40_Part_11': 130, 'Q40_OTHER': 131, 'Q42_Part_1': 132, 'Q42_Part_2': 133, 'Q42_Part_3': 134, 'Q42_Part_4': 135, 'Q42_Part_5': 136, 'Q42_Part_6': 137, 'Q42_Part_7': 138, 'Q42_Part_8': 139, 'Q42_Part_9': 140, 'Q42_Part_10': 141, 'Q42_Part_11': 142, 'Q42_OTHER': 143, 'Q27_B_Part_1': 144, 'Q27_B_Part_2': 145, 'Q27_B_Part_3': 146, 'Q27_B_Part_4': 147, 'Q27_B_Part_5': 148, 'Q27_B_Part_6': 149, 'Q27_B_Part_7': 150, 'Q27_B_Part_8': 151, 'Q27_B_Part_9': 152, 'Q27_B_Part_10': 153, 'Q27_B_Part_11': 154, 'Q27_B_OTHER': 155, 'Q29_B_Part_1': 156, 'Q29_B_Part_2': 157, 'Q29_B_Part_3': 158, 'Q29_B_Part_4': 159, 'Q29_B_OTHER': 160, 'Q30_B_Part_1': 161, 'Q30_B_Part_2': 162, 'Q30_B_Part_3': 163, 'Q30_B_Part_4': 164, 'Q30_B_Part_5': 165, 'Q30_B_Part_6': 166, 'Q30_B_Part_7': 167, 'Q30_B_OTHER': 168, 'Q31_B_Part_1': 169, 'Q31_B_Part_2': 170, 'Q31_B_Part_3': 171, 'Q31_B_Part_4': 172, 'Q31_B_Part_5': 173, 'Q31_B_Part_6': 174, 'Q31_B_Part_7': 175, 'Q31_B_Part_8': 176, 'Q31_B_Part_9': 177, 'Q31_B_OTHER': 178, 'Q32_B_Part_1': 179, 'Q32_B_Part_2': 180, 'Q32_B_Part_3': 181, 'Q32_B_Part_4': 182, 'Q32_B_Part_5': 183, 'Q32_B_Part_6': 184, 'Q32_B_Part_7': 185, 'Q32_B_Part_8': 186, 'Q32_B_Part_9': 187, 'Q32_B_Part_10': 188, 'Q32_B_Part_11': 189, 'Q32_B_Part_12': 190, 'Q32_B_Part_13': 191, 'Q32_B_Part_14': 192, 'Q32_B_Part_15': 193, 'Q32_B_Part_16': 194, 'Q32_B_Part_17': 195, 'Q32_B_Part_18': 196, 'Q32_B_Part_19': 197, 'Q32_B_Part_20': 198, 'Q32_B_OTHER': 199, 'Q34_B_Part_1': 200, 'Q34_B_Part_2': 201, 'Q34_B_Part_3': 202, 'Q34_B_Part_4': 203, 'Q34_B_Part_5': 204, 'Q34_B_Part_6': 205, 'Q34_B_Part_7': 206, 'Q34_B_Part_8': 207, 'Q34_B_Part_9': 208, 'Q34_B_Part_10': 209, 'Q34_B_Part_11': 210, 'Q34_B_Part_12': 211, 'Q34_B_Part_13': 212, 'Q34_B_Part_14': 213, 'Q34_B_Part_15': 214, 'Q34_B_Part_16': 215, 'Q34_B_OTHER': 216, 'Q36_B_Part_1': 217, 'Q36_B_Part_2': 218, 'Q36_B_Part_3': 219, 'Q36_B_Part_4': 220, 'Q36_B_Part_5': 221, 'Q36_B_Part_6': 222, 'Q36_B_Part_7': 223, 'Q36_B_OTHER': 224, 'Q37_B_Part_1': 225, 'Q37_B_Part_2': 226, 'Q37_B_Part_3': 227, 'Q37_B_Part_4': 228, 'Q37_B_Part_5': 229, 'Q37_B_Part_6': 230, 'Q37_B_Part_7': 231, 'Q37_B_OTHER': 232, 'Q38_B_Part_1': 233, 'Q38_B_Part_2': 234, 'Q38_B_Part_3': 235, 'Q38_B_Part_4': 236, 'Q38_B_Part_5': 237, 'Q38_B_Part_6': 238, 'Q38_B_Part_7': 239, 'Q38_B_Part_8': 240, 'Q38_B_Part_9': 241, 'Q38_B_Part_10': 242, 'Q38_B_Part_11': 243, 'Q38_B_OTHER': 244}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'index', 'age', 'gender', 'Q3', 'Q5', 'Q6', 'Q8', 'Q15',\n",
       "       'Q22',\n",
       "       ...\n",
       "       'Q38_B_Part_3', 'Q38_B_Part_4', 'Q38_B_Part_5', 'Q38_B_Part_6',\n",
       "       'Q38_B_Part_7', 'Q38_B_Part_8', 'Q38_B_Part_9', 'Q38_B_Part_10',\n",
       "       'Q38_B_Part_11', 'Q38_B_OTHER'],\n",
       "      dtype='object', length=168)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eliminar_indices(df_unido, 'Q18_Part_1', 'Q38_A_OTHER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Unnamed: 0': 0, 'index': 1, 'age': 2, 'gender': 3, 'Q3': 4, 'Q5': 5, 'Q6': 6, 'Q8': 7, 'Q15': 8, 'Q22': 9, 'Q41': 10, 'Q7': 11, 'Q9': 12, 'Q24': 13, 'Q32': 14, 'Q34': 15, 'Q10_Part_1': 16, 'Q10_Part_2': 17, 'Q10_Part_3': 18, 'Q10_Part_4': 19, 'Q10_Part_5': 20, 'Q10_Part_6': 21, 'Q10_Part_7': 22, 'Q10_Part_8': 23, 'Q10_Part_9': 24, 'Q10_Part_10': 25, 'Q10_Part_11': 26, 'Q10_Part_12': 27, 'Q10_Part_13': 28, 'Q10_Part_14': 29, 'Q10_Part_15': 30, 'Q10_Part_16': 31, 'Q10_OTHER': 32, 'Q39_Part_1': 33, 'Q39_Part_2': 34, 'Q39_Part_3': 35, 'Q39_Part_4': 36, 'Q39_Part_5': 37, 'Q39_Part_6': 38, 'Q39_Part_7': 39, 'Q39_Part_8': 40, 'Q39_Part_9': 41, 'Q39_OTHER': 42, 'Q40_Part_1': 43, 'Q40_Part_2': 44, 'Q40_Part_3': 45, 'Q40_Part_4': 46, 'Q40_Part_5': 47, 'Q40_Part_6': 48, 'Q40_Part_7': 49, 'Q40_Part_8': 50, 'Q40_Part_9': 51, 'Q40_Part_10': 52, 'Q40_Part_11': 53, 'Q40_OTHER': 54, 'Q42_Part_1': 55, 'Q42_Part_2': 56, 'Q42_Part_3': 57, 'Q42_Part_4': 58, 'Q42_Part_5': 59, 'Q42_Part_6': 60, 'Q42_Part_7': 61, 'Q42_Part_8': 62, 'Q42_Part_9': 63, 'Q42_Part_10': 64, 'Q42_Part_11': 65, 'Q42_OTHER': 66, 'Q27_B_Part_1': 67, 'Q27_B_Part_2': 68, 'Q27_B_Part_3': 69, 'Q27_B_Part_4': 70, 'Q27_B_Part_5': 71, 'Q27_B_Part_6': 72, 'Q27_B_Part_7': 73, 'Q27_B_Part_8': 74, 'Q27_B_Part_9': 75, 'Q27_B_Part_10': 76, 'Q27_B_Part_11': 77, 'Q27_B_OTHER': 78, 'Q29_B_Part_1': 79, 'Q29_B_Part_2': 80, 'Q29_B_Part_3': 81, 'Q29_B_Part_4': 82, 'Q29_B_OTHER': 83, 'Q30_B_Part_1': 84, 'Q30_B_Part_2': 85, 'Q30_B_Part_3': 86, 'Q30_B_Part_4': 87, 'Q30_B_Part_5': 88, 'Q30_B_Part_6': 89, 'Q30_B_Part_7': 90, 'Q30_B_OTHER': 91, 'Q31_B_Part_1': 92, 'Q31_B_Part_2': 93, 'Q31_B_Part_3': 94, 'Q31_B_Part_4': 95, 'Q31_B_Part_5': 96, 'Q31_B_Part_6': 97, 'Q31_B_Part_7': 98, 'Q31_B_Part_8': 99, 'Q31_B_Part_9': 100, 'Q31_B_OTHER': 101, 'Q32_B_Part_1': 102, 'Q32_B_Part_2': 103, 'Q32_B_Part_3': 104, 'Q32_B_Part_4': 105, 'Q32_B_Part_5': 106, 'Q32_B_Part_6': 107, 'Q32_B_Part_7': 108, 'Q32_B_Part_8': 109, 'Q32_B_Part_9': 110, 'Q32_B_Part_10': 111, 'Q32_B_Part_11': 112, 'Q32_B_Part_12': 113, 'Q32_B_Part_13': 114, 'Q32_B_Part_14': 115, 'Q32_B_Part_15': 116, 'Q32_B_Part_16': 117, 'Q32_B_Part_17': 118, 'Q32_B_Part_18': 119, 'Q32_B_Part_19': 120, 'Q32_B_Part_20': 121, 'Q32_B_OTHER': 122, 'Q34_B_Part_1': 123, 'Q34_B_Part_2': 124, 'Q34_B_Part_3': 125, 'Q34_B_Part_4': 126, 'Q34_B_Part_5': 127, 'Q34_B_Part_6': 128, 'Q34_B_Part_7': 129, 'Q34_B_Part_8': 130, 'Q34_B_Part_9': 131, 'Q34_B_Part_10': 132, 'Q34_B_Part_11': 133, 'Q34_B_Part_12': 134, 'Q34_B_Part_13': 135, 'Q34_B_Part_14': 136, 'Q34_B_Part_15': 137, 'Q34_B_Part_16': 138, 'Q34_B_OTHER': 139, 'Q36_B_Part_1': 140, 'Q36_B_Part_2': 141, 'Q36_B_Part_3': 142, 'Q36_B_Part_4': 143, 'Q36_B_Part_5': 144, 'Q36_B_Part_6': 145, 'Q36_B_Part_7': 146, 'Q36_B_OTHER': 147, 'Q37_B_Part_1': 148, 'Q37_B_Part_2': 149, 'Q37_B_Part_3': 150, 'Q37_B_Part_4': 151, 'Q37_B_Part_5': 152, 'Q37_B_Part_6': 153, 'Q37_B_Part_7': 154, 'Q37_B_OTHER': 155, 'Q38_B_Part_1': 156, 'Q38_B_Part_2': 157, 'Q38_B_Part_3': 158, 'Q38_B_Part_4': 159, 'Q38_B_Part_5': 160, 'Q38_B_Part_6': 161, 'Q38_B_Part_7': 162, 'Q38_B_Part_8': 163, 'Q38_B_Part_9': 164, 'Q38_B_Part_10': 165, 'Q38_B_Part_11': 166, 'Q38_B_OTHER': 167}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'index', 'age', 'gender', 'Q3', 'Q5', 'Q6', 'Q8', 'Q15',\n",
       "       'Q22', 'Q41', 'Q7', 'Q9', 'Q24', 'Q32', 'Q34', 'Q10_Part_1',\n",
       "       'Q10_Part_2', 'Q10_Part_3', 'Q10_Part_4', 'Q10_Part_5', 'Q10_Part_6',\n",
       "       'Q10_Part_7', 'Q10_Part_8', 'Q10_Part_9', 'Q10_Part_10', 'Q10_Part_11',\n",
       "       'Q10_Part_12', 'Q10_Part_13', 'Q10_Part_14', 'Q10_Part_15',\n",
       "       'Q10_Part_16', 'Q10_OTHER', 'Q39_Part_1', 'Q39_Part_2', 'Q39_Part_3',\n",
       "       'Q39_Part_4', 'Q39_Part_5', 'Q39_Part_6', 'Q39_Part_7', 'Q39_Part_8',\n",
       "       'Q39_Part_9', 'Q39_OTHER'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eliminar_indices(df_unido, 'Q40_Part_1', 'Q38_B_OTHER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0\n",
      "index\n",
      "age\n",
      "gender\n",
      "Q3\n",
      "Q5\n",
      "Q6\n",
      "Q8\n",
      "Q15\n",
      "Q22\n",
      "Q41\n",
      "Q7\n",
      "Q9\n",
      "Q24\n",
      "Q32\n",
      "Q34\n",
      "Q10_Part_1\n",
      "Q10_Part_2\n",
      "Q10_Part_3\n",
      "Q10_Part_4\n",
      "Q10_Part_5\n",
      "Q10_Part_6\n",
      "Q10_Part_7\n",
      "Q10_Part_8\n",
      "Q10_Part_9\n",
      "Q10_Part_10\n",
      "Q10_Part_11\n",
      "Q10_Part_12\n",
      "Q10_Part_13\n",
      "Q10_Part_14\n",
      "Q10_Part_15\n",
      "Q10_Part_16\n",
      "Q10_OTHER\n",
      "Q39_Part_1\n",
      "Q39_Part_2\n",
      "Q39_Part_3\n",
      "Q39_Part_4\n",
      "Q39_Part_5\n",
      "Q39_Part_6\n",
      "Q39_Part_7\n",
      "Q39_Part_8\n",
      "Q39_Part_9\n",
      "Q39_OTHER\n"
     ]
    }
   ],
   "source": [
    "for i in df_unido.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reemplazar_comas(columna):\n",
    "    try:\n",
    "        patron = ','\n",
    "        return re.sub(patron, ';', columna)\n",
    "    except:\n",
    "        return np.nan\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columna in df_unido.columns:\n",
    "    df_unido[columna] = df_unido[columna].apply(reemplazar_comas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reemplazar_punto_comas(columna):\n",
    "    try:\n",
    "        patron = ';'\n",
    "        return re.sub(patron, ',', columna)\n",
    "    except:\n",
    "        return np.nan\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardamos los datos unidos con las columnas eliminadas en un archivo de csv\n",
    "df_unido.to_csv('../datos/datos_unidos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtramos por Data Analysts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtramos el nuevo dataframe unido por respuestas de personas que se identifican como \n",
    "# Business Analyst o Data Analyst\n",
    "df_da_ba = df_unido[(df_unido [\"Q5\"] == \"Business Analyst\") | (df_unido [\"Q5\"] == \"Data Analyst\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q15</th>\n",
       "      <th>Q22</th>\n",
       "      <th>...</th>\n",
       "      <th>Q39_Part_1</th>\n",
       "      <th>Q39_Part_2</th>\n",
       "      <th>Q39_Part_3</th>\n",
       "      <th>Q39_Part_4</th>\n",
       "      <th>Q39_Part_5</th>\n",
       "      <th>Q39_Part_6</th>\n",
       "      <th>Q39_Part_7</th>\n",
       "      <th>Q39_Part_8</th>\n",
       "      <th>Q39_Part_9</th>\n",
       "      <th>Q39_OTHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50-54</td>\n",
       "      <td>Man</td>\n",
       "      <td>Belgium</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>20+ years</td>\n",
       "      <td>Python</td>\n",
       "      <td>1-2 years</td>\n",
       "      <td>5-9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22-24</td>\n",
       "      <td>Nonbinary</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>&lt; 1 years</td>\n",
       "      <td>R</td>\n",
       "      <td>I do not use machine learning methods</td>\n",
       "      <td>3-4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30-34</td>\n",
       "      <td>Woman</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>3-5 years</td>\n",
       "      <td>R</td>\n",
       "      <td>I do not use machine learning methods</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I do not share my work publicly</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22-24</td>\n",
       "      <td>Man</td>\n",
       "      <td>China</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>&lt; 1 years</td>\n",
       "      <td>Python</td>\n",
       "      <td>1-2 years</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40-44</td>\n",
       "      <td>Man</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>1-3 years</td>\n",
       "      <td>R</td>\n",
       "      <td>1-2 years</td>\n",
       "      <td>1-2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I do not share my work publicly</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  index    age     gender                        Q3  \\\n",
       "16         NaN    NaN  50-54        Man                   Belgium   \n",
       "32         NaN    NaN  22-24  Nonbinary  United States of America   \n",
       "33         NaN    NaN  30-34      Woman                     Egypt   \n",
       "46         NaN    NaN  22-24        Man                     China   \n",
       "52         NaN    NaN  40-44        Man              South Africa   \n",
       "\n",
       "              Q5         Q6      Q8                                    Q15  \\\n",
       "16  Data Analyst  20+ years  Python                              1-2 years   \n",
       "32  Data Analyst  < 1 years       R  I do not use machine learning methods   \n",
       "33  Data Analyst  3-5 years       R  I do not use machine learning methods   \n",
       "46  Data Analyst  < 1 years  Python                              1-2 years   \n",
       "52  Data Analyst  1-3 years       R                              1-2 years   \n",
       "\n",
       "    Q22  ... Q39_Part_1 Q39_Part_2 Q39_Part_3 Q39_Part_4 Q39_Part_5  \\\n",
       "16  5-9  ...        NaN        NaN        NaN        NaN        NaN   \n",
       "32  3-4  ...        NaN        NaN        NaN        NaN        NaN   \n",
       "33    0  ...        NaN        NaN        NaN        NaN        NaN   \n",
       "46    0  ...        NaN        NaN        NaN        NaN        NaN   \n",
       "52  1-2  ...        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "   Q39_Part_6 Q39_Part_7 Q39_Part_8                       Q39_Part_9 Q39_OTHER  \n",
       "16        NaN        NaN        NaN                              NaN       NaN  \n",
       "32        NaN        NaN        NaN                              NaN       NaN  \n",
       "33        NaN        NaN        NaN  I do not share my work publicly       NaN  \n",
       "46        NaN        NaN        NaN                              NaN       NaN  \n",
       "52        NaN        NaN        NaN  I do not share my work publicly       NaN  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_da_ba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardamos los datos unidos con las columnas eliminadas en un archivo de csv\n",
    "df_da_ba.to_csv('../datos/datos_da_ba.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q15</th>\n",
       "      <th>Q22</th>\n",
       "      <th>...</th>\n",
       "      <th>Q39_Part_1</th>\n",
       "      <th>Q39_Part_2</th>\n",
       "      <th>Q39_Part_3</th>\n",
       "      <th>Q39_Part_4</th>\n",
       "      <th>Q39_Part_5</th>\n",
       "      <th>Q39_Part_6</th>\n",
       "      <th>Q39_Part_7</th>\n",
       "      <th>Q39_Part_8</th>\n",
       "      <th>Q39_Part_9</th>\n",
       "      <th>Q39_OTHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50-54</td>\n",
       "      <td>Man</td>\n",
       "      <td>India</td>\n",
       "      <td>Other</td>\n",
       "      <td>5-10 years</td>\n",
       "      <td>Python</td>\n",
       "      <td>5-10 years</td>\n",
       "      <td>3-4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GitHub</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index    age gender     Q3     Q5          Q6      Q8  \\\n",
       "0         NaN    NaN  50-54    Man  India  Other  5-10 years  Python   \n",
       "\n",
       "          Q15  Q22  ... Q39_Part_1 Q39_Part_2 Q39_Part_3 Q39_Part_4  \\\n",
       "0  5-10 years  3-4  ...        NaN        NaN        NaN    GitHub    \n",
       "\n",
       "  Q39_Part_5 Q39_Part_6 Q39_Part_7 Q39_Part_8 Q39_Part_9 Q39_OTHER  \n",
       "0        NaN    Kaggle         NaN        NaN        NaN       NaN  \n",
       "\n",
       "[1 rows x 43 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unido.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'gender', 'Q3', 'Q5', 'Q6', 'Q8', 'Q15', 'Q22', 'Q41', 'Q7',\n",
       "       'Q9', 'Q24', 'Q32', 'Q34', 'Q10_Part_1', 'Q10_Part_2', 'Q10_Part_3',\n",
       "       'Q10_Part_4', 'Q10_Part_5', 'Q10_Part_6', 'Q10_Part_7', 'Q10_Part_8',\n",
       "       'Q10_Part_9', 'Q10_Part_10', 'Q10_Part_11', 'Q10_Part_12',\n",
       "       'Q10_Part_13', 'Q10_Part_14', 'Q10_Part_15', 'Q10_Part_16', 'Q10_OTHER',\n",
       "       'Q39_Part_1', 'Q39_Part_2', 'Q39_Part_3', 'Q39_Part_4', 'Q39_Part_5',\n",
       "       'Q39_Part_6', 'Q39_Part_7', 'Q39_Part_8', 'Q39_Part_9', 'Q39_OTHER'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eliminar_etiqueta(df_unido, *['index', 'Unnamed: 0'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adalabenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b8bbabd87d3ce636409443d1398e5656bf795e33c753b5e821c4b969f4e6c41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
